{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3b778e-8c9f-4272-be7e-cc2069235091",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc04dcd-f000-43c2-9e0a-4aa7e41b4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Preprocessing original dataset *************\n",
      "categorical_variables: ['mrt_station', 'hour', 'status', 'day_in_a_week', 'month']\n",
      "metro_flow index:  [1] \n",
      "categorical indices:  [0, 2, 10, 26, 27] \n",
      "numerical indices:  [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "\n",
      "\n",
      "7 unique mrt_station:\t ['中山', '北投', '北門', '古亭', '士林', '大橋頭', '松山']\n",
      "mrt_station is a string!\n",
      "24 unique hour:\t [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 2, 3, 4]\n",
      "5 unique status:\t ['良好', '普通', '對敏感族群不健康', nan, '對所有族群不健康']\n",
      "status is a string!\n",
      "7 unique day_in_a_week:\t [2, 3, 4, 5, 6, 0, 1]\n",
      "12 unique month:\t [6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5]\n",
      "Processing string categories\n",
      "\tFirst occurance of 中山: 0\n",
      "\tFirst occurance of 北投: 1\n",
      "\tFirst occurance of 北門: 2\n",
      "\tFirst occurance of 古亭: 3\n",
      "\tFirst occurance of 士林: 4\n",
      "\tFirst occurance of 大橋頭: 5\n",
      "\tFirst occurance of 松山: 6\n",
      "\tFirst occurance of 良好: 0\n",
      "\tFirst occurance of 普通: 54\n",
      "\tFirst occurance of 對敏感族群不健康: 8025\n",
      "\tFirst occurance of 對所有族群不健康: 16068\n",
      "\n",
      "Train-val-test split\n",
      "\tTrain start index: 0\n",
      "\tVal start index: 55827\n",
      "\tTest start index: 63802\n",
      "Y_test_raw mean:  \t 2296.5136033099297\n",
      "Y_test_raw median:\t 1749.5\n",
      "Y_test_raw std:   \t 2050.6766605779653\n",
      "\n",
      "************* Preprocessing reshaped dataset *************\n",
      "categorical_variables: ['day_in_a_week', 'month', 'hour', '中山_status', '北投_status', '北門_status', '古亭_status', '士林_status', '大橋頭_status', '松山_status']\n",
      "metro_flow index:  [0, 1, 2, 3, 4, 5, 6] \n",
      "categorical indices:  [14, 15, 16, 36, 37, 38, 39, 40, 41, 42] \n",
      "numerical indices:  [7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147]\n",
      "\n",
      "\n",
      "7 unique day_in_a_week:\t [2.0, 3.0, 4.0, 5.0, 6.0, 0.0, 1.0]\n",
      "12 unique month:\t [6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "24 unique hour:\t [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 0.0, 1.0, 2.0, 3.0, 4.0]\n",
      "4 unique 中山_status:\t ['良好', '普通', '對敏感族群不健康', nan]\n",
      "中山_status is a string!\n",
      "4 unique 北投_status:\t ['良好', '普通', '對敏感族群不健康', nan]\n",
      "北投_status is a string!\n",
      "5 unique 北門_status:\t ['良好', '普通', nan, '對敏感族群不健康', '對所有族群不健康']\n",
      "北門_status is a string!\n",
      "5 unique 古亭_status:\t ['良好', '普通', '對敏感族群不健康', '對所有族群不健康', nan]\n",
      "古亭_status is a string!\n",
      "4 unique 士林_status:\t ['良好', '普通', nan, '對敏感族群不健康']\n",
      "士林_status is a string!\n",
      "4 unique 大橋頭_status:\t ['良好', '普通', nan, '對敏感族群不健康']\n",
      "大橋頭_status is a string!\n",
      "5 unique 松山_status:\t ['良好', '普通', '對敏感族群不健康', '對所有族群不健康', nan]\n",
      "松山_status is a string!\n",
      "Processing string categories\n",
      "\tFirst occurance of 良好: 0\n",
      "\tFirst occurance of 普通: 5\n",
      "\tFirst occurance of 對敏感族群不健康: 1123\n",
      "\tFirst occurance of 對所有族群不健康: 2254\n",
      "\n",
      "Train-val-test split\n",
      "\tTrain start index: 0\n",
      "\tVal start index: 7904\n",
      "\tTest start index: 9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\anaconda3\\envs\\FinTech\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "C:\\Users\\vital\\anaconda3\\envs\\FinTech\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1384: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test_raw mean:  \t 2309.976980965029\n",
      "Y_test_raw median:\t 1760.0\n",
      "Y_test_raw std:   \t 2051.8194300373616\n"
     ]
    }
   ],
   "source": [
    "import preprocess\n",
    "\n",
    "print(\"************* Preprocessing original dataset *************\")\n",
    "original_dataset = preprocess.DatasetPreprocess(\"FinalData.csv\", sequence_length=0, is_dataset_reshaped = False)\n",
    "\n",
    "print(\"\\n************* Preprocessing reshaped dataset *************\")\n",
    "reshaped_dataset = preprocess.DatasetPreprocess(\"FinalData_Reshaped.csv\", sequence_length=0, is_dataset_reshaped = True)\n",
    "\n",
    "\n",
    "import sklearn.linear_model\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def print_metrics(model, Y_inverse_transform, X, Y):\n",
    "    Y_hat = model.predict(X)\n",
    "    if Y_hat.ndim < 2:\n",
    "        Y_hat = Y_hat[:, None]\n",
    "\n",
    "    MSE = np.mean((Y_hat - Y) ** 2)\n",
    "    orig_MSE = np.mean((Y_inverse_transform(Y_hat) - Y_inverse_transform(Y)) ** 2)\n",
    "    print(\"\\tMSE:\", MSE)\n",
    "    print(\"\\tOriginal scale MSE:\", orig_MSE)\n",
    "\n",
    "    print(\"\\n\\tRMSE:\", np.sqrt(MSE))\n",
    "    print(\"\\tOriginal scale RMSE:\", np.sqrt(orig_MSE))\n",
    "\n",
    "    print(\"\\n\\tMAE:\", np.mean(np.abs(Y_hat - Y)))\n",
    "    print(\"\\tOriginal scale MAE:\", np.mean(np.abs(Y_inverse_transform(Y_hat) - Y_inverse_transform(Y))))\n",
    "\n",
    "def print_all_metrics(model, dataset):\n",
    "    print(\"Train metrics:\")\n",
    "    print_metrics(model, dataset.Y_inverse_transform, dataset.X_train, dataset.Y_train)\n",
    "    print(\"\\nValidation metrics:\")\n",
    "    print_metrics(model, dataset.Y_inverse_transform, dataset.X_val,   dataset.Y_val)\n",
    "    print(\"\\nTest metrics:\")\n",
    "    print_metrics(model, dataset.Y_inverse_transform, dataset.X_test,  dataset.Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5704a5-1025-4c32-b35f-51001461364c",
   "metadata": {},
   "source": [
    "# Sklearn LinearRegression - original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9067e9e7-b142-4d40-a7ff-2095bacc6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "\tMSE: 0.16411246282561986\n",
      "\tOriginal scale MSE: 685651.3664878189\n",
      "\n",
      "\tRMSE: 0.40510796440655156\n",
      "\tOriginal scale RMSE: 828.0406792469914\n",
      "\n",
      "\tMAE: 0.2817718927164729\n",
      "\tOriginal scale MAE: 575.9417487124706\n",
      "\n",
      "Validation metrics:\n",
      "\tMSE: 0.1992902363849208\n",
      "\tOriginal scale MSE: 832621.8530410704\n",
      "\n",
      "\tRMSE: 0.4464193503701657\n",
      "\tOriginal scale RMSE: 912.4811521566187\n",
      "\n",
      "\tMAE: 0.30151310421198946\n",
      "\tOriginal scale MAE: 616.2927850093064\n",
      "\n",
      "Test metrics:\n",
      "\tMSE: 0.23655225958321435\n",
      "\tOriginal scale MSE: 988300.2011940563\n",
      "\n",
      "\tRMSE: 0.4863663841007254\n",
      "\tOriginal scale RMSE: 994.1328891018827\n",
      "\n",
      "\tMAE: 0.32336636172997824\n",
      "\tOriginal scale MAE: 660.9608433760754\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "LR = sklearn.linear_model.LinearRegression(n_jobs=-1).fit(original_dataset.X_train, np.ravel(original_dataset.Y_train))\n",
    "\n",
    "# Evaluation\n",
    "print_all_metrics(LR, original_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dcc7d8-689c-4321-9181-519d505e6369",
   "metadata": {},
   "source": [
    "# Sklearn LinearRegression - reshaped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f72095-46e8-471c-b6c0-38dd14fd7ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "\tMSE: 0.04111878035586768\n",
      "\tOriginal scale MSE: 117630.11954971934\n",
      "\n",
      "\tRMSE: 0.20277766236907774\n",
      "\tOriginal scale RMSE: 342.9724763734247\n",
      "\n",
      "\tMAE: 0.13448463512076367\n",
      "\tOriginal scale MAE: 220.35458160372357\n",
      "\n",
      "Validation metrics:\n",
      "\tMSE: 0.1117463203669921\n",
      "\tOriginal scale MSE: 291242.74579741806\n",
      "\n",
      "\tRMSE: 0.3342847893144289\n",
      "\tOriginal scale RMSE: 539.6691076923137\n",
      "\n",
      "\tMAE: 0.2021691317811276\n",
      "\tOriginal scale MAE: 325.99686152105414\n",
      "\n",
      "Test metrics:\n",
      "\tMSE: 0.09498425688054864\n",
      "\tOriginal scale MSE: 240725.14405229915\n",
      "\n",
      "\tRMSE: 0.3081951603782068\n",
      "\tOriginal scale RMSE: 490.63748741030696\n",
      "\n",
      "\tMAE: 0.21444958734371672\n",
      "\tOriginal scale MAE: 340.92698509771645\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "LR = sklearn.linear_model.LinearRegression(n_jobs=-1).fit(reshaped_dataset.X_train, reshaped_dataset.Y_train)\n",
    "\n",
    "# Evaluation\n",
    "print_all_metrics(LR, reshaped_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb5714-5e8d-476f-8d4e-af77fe7bd909",
   "metadata": {},
   "source": [
    "# Sklearn MLP - original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fda6b75-b0e3-48d0-946c-112cc25ba9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "\tMSE: 0.01730874334933838\n",
      "\tOriginal scale MSE: 72314.8219539614\n",
      "\n",
      "\tRMSE: 0.1315626974082638\n",
      "\tOriginal scale RMSE: 268.91415350249116\n",
      "\n",
      "\tMAE: 0.07195235365162225\n",
      "\tOriginal scale MAE: 147.0706108639159\n",
      "\n",
      "Validation metrics:\n",
      "\tMSE: 0.07155279610540236\n",
      "\tOriginal scale MSE: 298943.0027494203\n",
      "\n",
      "\tRMSE: 0.26749354404434206\n",
      "\tOriginal scale RMSE: 546.7568040266351\n",
      "\n",
      "\tMAE: 0.1807632307682581\n",
      "\tOriginal scale MAE: 369.4800436903195\n",
      "\n",
      "Test metrics:\n",
      "\tMSE: 0.07875882948372227\n",
      "\tOriginal scale MSE: 329049.3490179047\n",
      "\n",
      "\tRMSE: 0.28064003542567173\n",
      "\tOriginal scale RMSE: 573.628232410073\n",
      "\n",
      "\tMAE: 0.19104452391837765\n",
      "\tOriginal scale MAE: 390.4950068891639\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "MLP = MLPRegressor(max_iter=2000, hidden_layer_sizes = (10000)).fit(original_dataset.X_train, np.ravel(original_dataset.Y_train))\n",
    "\n",
    "# Evaluation\n",
    "print_all_metrics(MLP, original_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ea94c2-8561-4088-b314-97d0a6034a34",
   "metadata": {},
   "source": [
    "# Sklearn MLP - reshaped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793c1a31-c1a1-402b-ab4a-acc4b685cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "\tMSE: 0.0027649284353395537\n",
      "\tOriginal scale MSE: 8925.031539691243\n",
      "\n",
      "\tRMSE: 0.05258258680722691\n",
      "\tOriginal scale RMSE: 94.47238506405586\n",
      "\n",
      "\tMAE: 0.038610080363767084\n",
      "\tOriginal scale MAE: 65.21900988839606\n",
      "\n",
      "Validation metrics:\n",
      "\tMSE: 0.054362414741242815\n",
      "\tOriginal scale MSE: 141260.41282386414\n",
      "\n",
      "\tRMSE: 0.2331574891382278\n",
      "\tOriginal scale RMSE: 375.84626221882814\n",
      "\n",
      "\tMAE: 0.14351751676608004\n",
      "\tOriginal scale MAE: 238.99639601140163\n",
      "\n",
      "Test metrics:\n",
      "\tMSE: 0.07883269756393908\n",
      "\tOriginal scale MSE: 182757.1142687961\n",
      "\n",
      "\tRMSE: 0.28077161103633513\n",
      "\tOriginal scale RMSE: 427.5010108395021\n",
      "\n",
      "\tMAE: 0.18599792667577048\n",
      "\tOriginal scale MAE: 295.76378269751325\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "MLP = MLPRegressor(max_iter=2000, hidden_layer_sizes = (10000)).fit(reshaped_dataset.X_train, reshaped_dataset.Y_train)\n",
    "\n",
    "# Evaluation\n",
    "print_all_metrics(MLP, reshaped_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
